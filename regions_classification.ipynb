{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e051a0aa-14db-4cdf-9b48-3ee47e3920ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8fcf8-dd9b-439a-a798-1eaa1961e1ad",
   "metadata": {},
   "source": [
    "# Read the driving factors rasters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ed4ee4-ae6a-4d2d-85ce-c235188b152b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEM_factors = ['aspect', 'slope', 'elevation']\n",
    "\n",
    "climate_factors = ['soil_type', '10m_u_component_of_wind', '10m_v_component_of_wind', '2m_temperature', 'evaporation_from_vegetation_transpiration',\n",
    "             'runoff', 'soil_temperature_level_1',   'total_precipitation'\n",
    "                , 'volumetric_soil_water_layer_1','total_evaporation',]\n",
    "\n",
    "population_factors = ['population_density_GPWv4']\n",
    "\n",
    "nb_factors = len(climate_factors) + len(DEM_factors)  + len(population_factors)\n",
    "\n",
    "nb_years, nb_pixels_height, nb_pixels_width = 21, 126, 229\n",
    "no_data = 255\n",
    "years = np.array([2002+i for i in range(nb_years)])\n",
    "\n",
    "\n",
    "factors = np.ndarray((nb_factors,nb_years,nb_pixels_height,nb_pixels_width))\n",
    "\n",
    "\n",
    "c_f = 0\n",
    "\n",
    "for i,factor in enumerate(DEM_factors):\n",
    "    src = rasterio.open(f'./rasters/driving_factors/raster-DEM-{factor}_5km.tif')\n",
    "    arr = src.read(1)\n",
    "    for j in range(21):\n",
    "        factors[c_f + i][j] = arr\n",
    "    \n",
    "c_f += len(DEM_factors)\n",
    "\n",
    "for i,factor in enumerate(climate_factors):\n",
    "    src = rasterio.open(f'./rasters/driving_factors/raster-{factor}_5km.tif')\n",
    "    arr = src.read()\n",
    "    factors[c_f + i] = arr\n",
    "       \n",
    "c_f += len(climate_factors)\n",
    "\n",
    "for i,factor in enumerate(population_factors):\n",
    "    src = rasterio.open(f'./rasters/driving_factors/raster-{factor}_5km.tif')\n",
    "    arr = src.read()\n",
    "    for j in range(21):\n",
    "        factors[c_f + i][j] = arr[(j + 2002)//5 - 400]\n",
    "c_f += len(population_factors)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78913e6a-cba8-4ce9-9461-7471528fe619",
   "metadata": {},
   "source": [
    "# Read the Regionalization Rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074cb29-4e0b-4150-9300-2a3f4d140efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regions =  np.ndarray((4, nb_pixels_height,nb_pixels_width))\n",
    "for i in range(5, 9):\n",
    "    src = rasterio.open(f\"./rasters/driving_factors/Skater_results/SkReg{i}.tif\")\n",
    "    regions[i-5] = src.read(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56048d0-37b6-4ace-b381-eae8c8c995dd",
   "metadata": {},
   "source": [
    "## Create a dataset file using the driving factors\n",
    "### For the climate factors, compute the average values of each 5 years period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61885a-1801-460c-b69b-decd5f1e67f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns =   climate_factors + DEM_factors + population_factors + ['regions']\n",
    "\n",
    "# get coordinates where it contains a value \n",
    "coordinates = np.argwhere(regions[0] > 0)\n",
    "\n",
    "#create a dataset with all the driving factors\n",
    "dataset = np.ndarray((len(coordinates), len(DEM_factors) + 1 + 4*(len(climate_factors) - 1)  + len(population_factors)*5 + 4) )\n",
    "\n",
    "# periods to compute the averages\n",
    "frontiers = [0,5,10,15,22]\n",
    "for i,c in enumerate(coordinates):\n",
    "    \n",
    "    # for DEM and soil type\n",
    "    for j in range(len(DEM_factors) + 1):\n",
    "        dataset[i][j] = factors[j][0][c[0]][c[1]]\n",
    "    idx = len(DEM_factors) + 1\n",
    "    for j in range(len(climate_factors)-1):\n",
    "        l = []\n",
    "        for y in range(len(years)):\n",
    "            l.append(factors[idx+j][y][c[0]][c[1]])\n",
    "            \n",
    "        # to have the average of the different slices [2002 to 2006],[2007 to 2011],[2012 to 2016], [2017 to 2022]\n",
    "        for k in range(len(frontiers) - 1):\n",
    "            dataset[i][idx + j*4+ k] = np.average(l[frontiers[k]:frontiers[k+1]]) \n",
    "        \n",
    "    idx += (len(climate_factors)-1)*4\n",
    "    for j in range(5):\n",
    "        dataset[i][j+idx] = factors[len(climate_factors) + len(DEM_factors)][j*5][c[0]][c[1]]\n",
    "    idx += 5\n",
    "    # target\n",
    "    for j in range(4):\n",
    "        dataset[i][idx+j] = regions[j][c[0]][c[1]]\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d086e9f-de50-4556-9eaf-94660d75bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the columns list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ebfea6-3681-4d4a-abdc-b2aec8f58b14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "climate_factors_ext = ['soil_type']\n",
    "for j in range(1, len(climate_factors)):\n",
    "    for i in range(4):\n",
    "        climate_factors_ext.append(climate_factors[j]+'_' +str(2002+i*5))\n",
    "\n",
    "population_factors_ext = []\n",
    "for i in range(5):\n",
    "    population_factors_ext.append('population_density_GPWv4'+'_'+str(2000+i*5))\n",
    "regions_ext = []\n",
    "for i in range(5,9):\n",
    "    regions_ext.append('region'+str(i))\n",
    "\n",
    "columns =   DEM_factors + climate_factors_ext + population_factors_ext + regions_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f8055e-b04a-49e4-a790-e4d02ca81375",
   "metadata": {},
   "source": [
    "## Create a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0c9de2-4dcf-4cb9-8865-8639b4ce90c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2853a9-8a2b-4fef-91c2-3a92a1dc32c7",
   "metadata": {},
   "source": [
    "## Compute statistical data on the Dataframe for all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93691e6-ce74-43b3-950f-c1d52432bc23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df.describe(include = 'all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0232c7b5-16ab-407f-b999-f0866aaf1447",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Have a list of all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee09a1-cd15-455b-a0c2-23f631b63ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = DEM_factors + climate_factors_ext + population_factors_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de806d8-6da9-41b7-a41d-7fffe1620646",
   "metadata": {},
   "source": [
    "# Train a Random Forest Classifier for each regionalization and display:\n",
    "1. The accuracy of the training and the test\n",
    "1. The accuract, the preceision, the recall, and F1-score of the prediction\n",
    "1. The confusion Matrix\n",
    "1. The most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53525be8-b0c6-4188-a4e9-59856a877d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import operator\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "accuracies_train = []\n",
    "accuracies_test = []\n",
    "precisions_test = []\n",
    "recalls_test = []\n",
    "f1s_test = []\n",
    "misclassified_rows = []\n",
    "for i in range(5,9):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.drop(regions_ext, axis=1), df[f\"region{i}\"], test_size=0.2)\n",
    "   \n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    accuracies_train.append(accuracy_score(y_train, y_train_pred))\n",
    "       \n",
    "    display(Markdown(f\"---\"))\n",
    "    display(Markdown(f\"# Results for {i} Regions\"))\n",
    "    \n",
    "    clf.predict(X_test)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "\n",
    "    display(Markdown(f\"### Accuracy (Test and Training) comparison\"))\n",
    "    accuracy_df = pd.DataFrame({\n",
    "        'Accuracy': ['Training', 'Test'],\n",
    "        'Value': [accuracy, accuracies_train[-1]]\n",
    "    })\n",
    "    display(accuracy_df)\n",
    "\n",
    "    display(Markdown(f\"### Evaluation Metrics for the Prediction\"))\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],\n",
    "        'Value': [accuracy, precision, recall, f1]\n",
    "    })\n",
    "    display(metrics_df)\n",
    "\n",
    "    accuracies_test.append(accuracy)\n",
    "    precisions_test.append(precision)\n",
    "    recalls_test.append(recall)\n",
    "    f1s_test.append(f1)\n",
    "    \n",
    "\n",
    "    # Create a confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    display(Markdown(f\"## Confusion Matrix\"))\n",
    "    \n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()        \n",
    "    \n",
    "\n",
    "    display(Markdown(f\"## Features importance\"))\n",
    "    # Get feature importances\n",
    "    feature_importances = clf.feature_importances_\n",
    "    feature_names = np.array(list(features))  \n",
    "\n",
    "    # Sort features based on importance\n",
    "    sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "    # Plot the top N most important features\n",
    "    top_n = 10  # You can adjust this based on the number of features you want to display\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(top_n), feature_importances[sorted_idx][:top_n], align=\"center\")\n",
    "    plt.xticks(range(top_n), feature_names[sorted_idx][:top_n], rotation=90)\n",
    "    plt.xlabel(\"Feature\")\n",
    "    plt.ylabel(\"Importance\")\n",
    "    plt.title(f\"Top {top_n} Most Important Features - Random Forest Classifier\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5919b908-7726-4a1a-a717-735bf6468e5e",
   "metadata": {},
   "source": [
    "# Plot the Training and the Test accuracy according to the number of regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027eddf-2f7c-43ae-868c-f4ec8cf19c94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "regions_c = [5,6,7,8]\n",
    "\n",
    "# Plotting the training accuracy\n",
    "plt.plot(regions_c, accuracies_train, label='Training Accuracy', marker='o')\n",
    "\n",
    "# Plotting the test accuracy\n",
    "plt.plot(regions_c, accuracies_test, label='Test Accuracy', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Number of Regions')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy Over Region Numbers')\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot as an image\n",
    "plt.savefig('accuracy_plot.png')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc4468-0ab9-4c20-9e94-fb4f8c17c1ed",
   "metadata": {},
   "source": [
    "# Plot the  Test Precision according to the number of regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7727ea2a-5601-49ad-8354-2697d6af0c20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "regions_c = [5,6,7,8]\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the test accuracy\n",
    "plt.plot(regions_c, precisions_test, label='Test Precision', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Number of Regions')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Test Precision Over Region Numbers')\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot as an image\n",
    "plt.savefig('precision_plot.png')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485b7703-df17-433c-8c45-be4ce4f2bbca",
   "metadata": {},
   "source": [
    "# Plot the the Test Recall according to the number of regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cbe9ff-af18-4e13-acb0-520668a9331a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "regions_c = [5,6,7,8]\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the test accuracy\n",
    "plt.plot(regions_c, recalls_test, label='Test Recall', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Number of Regions')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Test Recall Over Region Numbers')\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot as an image\n",
    "plt.savefig('recall_plot.png')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771d5333-a377-481c-b86f-6f3e75e7ccd8",
   "metadata": {},
   "source": [
    "# Plot the the Test F1-Score according to the number of regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a049f4d-eb6a-4322-a526-343d12fc5276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "regions_c = [5,6,7,8]\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the test accuracy\n",
    "plt.plot(regions_c, f1s_test, label='Test F1 Score', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Number of Regions')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Test F1 Score Over Region Numbers')\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot as an image\n",
    "plt.savefig('f1_plot.png')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
